<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Taylor Genetic Programming for Symbolic Regression</title>
    <link href="/2022/04/06/TaylorGP/"/>
    <url>/2022/04/06/TaylorGP/</url>
    
    <content type="html"><![CDATA[<p>Baihe He, Qiang Lu, Qingyun Yang, Jake Luo, and Zhiguang Wang.</p><p>Received:  24 March 2022 / Accepted: 14 April 2022.</p><h1 id="TaylorGP"><a href="#TaylorGP" class="headerlink" title="TaylorGP"></a>TaylorGP</h1><p>The paper  <a href="https://github.com/KGAE-CUP/TaylorGP/blob/main/img/Taylor_Symbolic_Regression_GECCO2022.pdf">Taylor Genetic Programming for Symbolic Regression</a>  has been accepted by <a href="https://gecco-2022.sigevo.org/HomePage">GECCO-2022</a> . You could also see our <a href="https://github.com/KGAE-CUP/TaylorGP/blob/main/img/Appendix_Taylor_Symbolic_Regression_GECCO2022.pdf">appendix</a> for more details.</p><h2 id="1-Abstract"><a href="#1-Abstract" class="headerlink" title="1.Abstract"></a>1.Abstract</h2><p>Genetic programming (GP) is a commonly used approach to solve symbolic regression (SR) problems. Compared with the machine learning or deep learning methods that depend on the pre-defined model and the training dataset for solving SR problems, GP is more focused on finding the solution in a search space. Although GP has good performance on large-scale benchmarks, it randomly transforms individuals to search results without taking advantage of the characteristics of the dataset.So, the search process of GP is usually slow, and the final results could be unstable. To guide GP by these characteristics, we propose a new method for SR, called Taylor genetic programming (TaylorGP). TaylorGP leverages a Taylor polynomial to approximate the symbolic equation that fits the dataset. It also utilizes the Taylor polynomial to extract the features of the symbolic equation: low order polynomial discrimination, variable separability, boundary, monotonic, and parity. GP is enhanced by these Taylor polynomial techniques. Experiments are conducted on three kinds of benchmarks: classical SR, machine learning, and physics. The experimental results show that TaylorGP not only has higher accuracy than the nine baseline methods, but also is faster in finding stable results.</p><h2 id="2-Code"><a href="#2-Code" class="headerlink" title="2. Code"></a>2. Code</h2><p>You could get the code from our <a href="https://github.com/KGAE-CUP/TaylorGP">github</a>.</p><h3 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h3><p>Make sure you have installed the following python version and pacakges before start running our code:</p><ul><li>python3.6~3.8</li><li>scikit-learn </li><li>numpy </li><li>sympy </li><li>pandas </li><li>time </li><li>copy </li><li>itertools </li><li>timeout_decorator </li><li>scipy </li><li>joblib </li><li>numbers </li><li>itertools </li><li>abc </li><li>warnings </li><li>math</li></ul><p>Our experiments were running in Ubuntu 18.04 with Intel(R) Xeon(R) Gold 5218R CPU @ 2.10GHz. </p><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>We provide an example to test whether the module required by Taylor GP is successfully installed: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">python TaylorGP.py<br></code></pre></td></tr></table></figure><p>In addition, you can run the specified dataset through the following method: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">python TaylorGP.py --fileName=<span class="hljs-string">&quot;Feynman/F24.tsv&quot;</span><br></code></pre></td></tr></table></figure><h2 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h2><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><p>We evaluate the performance of TaylorGP on three kinds of benchmarks: classical Symbolic Regression Benchmarks (<strong>SRB</strong>), Penn<br>Machine Learning Benchmarks (<strong>PMLB</strong>), and Feynman Symbolic Regression Benchmarks (<strong>FSRB</strong>) .(You could get them from directories GECCO, PMLB and Feynman respectively).The distribution of the total 81 benchmark sizes by samples and features is shown in the following. </p><img src="/img/img_TaylorGP/datasets_size.png" width="50%"><p>The details of these benchmarks are listed in the <a href="https://github.com/KGAE-CUP/TaylorGP/blob/main/img/Appendix_Taylor_Symbolic_Regression_GECCO2022.pdf">appendix</a>.</p><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><p>We compare TaylorGP with two kinds of baseline algorithms \footnote{The nine baseline algorithms are implemented in <a href="https://github.com/cavalab/srbench">SRBench</a> : four symbolic regression methods and five machine learning methods. The symbolic regression methods include <a href="https://github.com/trevorstephens/gplearn"><strong>GPlearn</strong></a>, FFX , geometric semantic genetic programming (<strong>GSGP</strong>) and bayesian symbolic regression (<strong>BSR</strong>). The machine learning methods include linear regression (<strong>LR</strong>), kernel ridge regression (<strong>KR</strong>), random forest regression (<strong>RF</strong>), support vector machines (<strong>SVM</strong>), and <strong>XGBoost</strong> . </p><p>As shown in the figure below , we illustrate the normalized <strong>R^2 scores</strong> of the ten algorithms running 30 times on all benchmarks. Since the normalized R^2 closer to 1 indicates better results, overall TaylorGP can find more accurate results than other algorithms.</p><img src="/img/img_TaylorGP/contact.jpg" width="50%"><p>Normalized R^2 comparisons of the ten SR methods on <strong>classical Symbolic Regression Benchmarks</strong></p><img src="/img/img_TaylorGP/GECCO.jpg" width="50%"><p>Normalized R^2 comparisons of the ten SR methods on <strong>Feynman Symbolic Regression Benchmarks</strong></p><img src="/img/img_TaylorGP/AIFeynman.jpg" width="50%"><p>Normalized R^2 comparisons of the ten SR methods on <strong>Penn Machine Learning Benchmarks</strong></p><img src="/img/img_TaylorGP/ML_father.jpg" width="50%">]]></content>
    
    
    <categories>
      
      <category>Evolutionary computation and Symbolic regression</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Symbolic regression</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Symbolic Regression Net</title>
    <link href="/2021/08/30/Symbolic%20Regression%20Net/"/>
    <url>/2021/08/30/Symbolic%20Regression%20Net/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu, Hu Xilei and Luo Yuanzhen .</p><p>Received:  28 October 20xx / Accepted: 28 October 20xx.</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>A Symbolic Regression (SR) method called SRNet to mine hidden semantics of each network layer in Neural Network (Multi-Layer Perceptron). SRNet is an evolutionary computing algorithm, leveraging Multi-Chromosomes Cartesian Genetic Programming (MCCGP) to find mathmatical formulas $f_i(x)*w_i+b_i$ for each network layer, white-boxing the black box.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://downloads.hindawi.com/journals/cin/2016/1021378.pdf">Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP/SRNet">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>Evolutionary computation and Symbolic regression</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Symbolic regression</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Trajectory Splicing</title>
    <link href="/2021/06/18/Trajectory-Splicing/"/>
    <url>/2021/06/18/Trajectory-Splicing/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu · Rencai Wang · Bin Yang · Zhiguang Wang.</p><p>Received:  23 September 2018 / 30 June 2019</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>With continued development of location-based systems, large amounts of trajectories become<br>available which record moving objects’ locations across time. If the trajectories collected by<br>different location-based systems come from the same moving object, they are spliceable<br>trajectories, which contribute to representing holistic behaviors of the moving object. In this<br>paper, we consider how to efficiently identify spliceable trajectories. More specifically, we<br>first formalize a spliced model to capture spliceable trajectories where their times are disjoint,<br>and the distances between them are close. Next, to efficiently implement the model, we design<br>three components: a disjoint time index, a directed acyclic graph of sub-trajectory location<br>connections, and two splice algorithms. The disjoint time index saves a disjoint time set of<br>each trajectory for querying disjoint time trajectories efficiently. The directed acyclic graph<br>contributes to discovering groups of spliceable trajectories. Based on the identified groups,<br>the splice algorithm findmaxCTR finds maximal groups containing all spliceable trajectories.<br>Although the splice algorithm is efficient in some practical applications, its running time is<br>exponential. Therefore, an approximate algorithm findApproxMaxCTR is proposed to find<br>trajectories which can be spliced with each other with a certain probability within polynomial<br>run time. Finally, experiments on two datasets demonstrate that the model and its components<br>are effective and efficient.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://www.cup.edu.cn/cise/docs/2021-04/99681f7bd5cc4f168be06704098772e4.pdf">KAIS-Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>轨迹分析和挖掘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>时空轨迹</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A semantic annotation based software knowledge sharing space</title>
    <link href="/2021/06/18/A-semantic-annotation-based-software-knowledge-sharing-space/"/>
    <url>/2021/06/18/A-semantic-annotation-based-software-knowledge-sharing-space/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu; Ming Chen; Zhiguang Wang.</p><p>Received: 2008 </p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Over the past several years, the software engineering needs large number of developers as the scale of software increasing. Therefore, the collaborative work and knowledge communication become difficult between team members. In order to improve knowledge sharing in team members, a semantic annotation based software knowledge sharing space (SKSS) is proposed. For implementing SKSS, at first, the knowledge in the process of software development is analyzed. Then, the SKSS is formalized based on the above analysis, and SKSS ontology is created. At last, the framework of semantic annotation is imported to implement SKSS, and all knowledge in software team will be connected into a completed knowledge net based on the framework.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4663375">IEEE-Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>知识图谱和智能问答</category>
      
    </categories>
    
    
    <tags>
      
      <tag>自然语言处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>An ant colony optimization algorithm for the one-dimensional cutting stock problem with multiple stock lengths</title>
    <link href="/2021/06/18/An-ant-colony-optimization-algorithm-for-the-one-dimensional-cutting-stock-problem-with-multiple-stock-lengths/"/>
    <url>/2021/06/18/An-ant-colony-optimization-algorithm-for-the-one-dimensional-cutting-stock-problem-with-multiple-stock-lengths/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu, Zhiguang Wang, Ming Chen.</p><p>Received: 2008 </p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>The Cutting Stock Problem (CSP) with multiple stock lengths is the NP-hard combinatorial optimization problem. In recent years, the CSP is researched by applying evolutionary approaches which includes Genetic Algorithm, Evolutionary Programming, et al. In the paper, an ant colony optimiation (ACO) algorithm for one-dimensional cutting stock problems with muliple stock lengths(MCSP) is presented, and mutation operatation is imported into the ACO in order to avoid the phenomenon of precocity and stagnation emerging. Based on the analysis of the algorithm, the ACO for MCSP has the same time complexity as CSP. Throught exmperiments study, the outcome shows that, compared with other algorithm, the algorithm takes a great improvement in the convergent speed and result optimization.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://dl.acm.org/doi/10.1109/ICNC.2008.208">ACM-Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>演化计算和符号回归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>演化计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Using genetic programming with prior formula knowledge to solve symbolic regression problem. Computational intelligence and neuroscience</title>
    <link href="/2021/06/18/Using%20genetic%20programming%20with%20prior%20formula%20knowledge%20to%20solve%20symbolic%20regression%20problem.%20Computational%20intelligence%20and%20neuroscience%20-%20%E5%89%AF%E6%9C%AC%20-%20%E5%89%AF%E6%9C%AC/"/>
    <url>/2021/06/18/Using%20genetic%20programming%20with%20prior%20formula%20knowledge%20to%20solve%20symbolic%20regression%20problem.%20Computational%20intelligence%20and%20neuroscience%20-%20%E5%89%AF%E6%9C%AC%20-%20%E5%89%AF%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu, Jun Ren, and Zhiguang Wang.</p><p>Received:  28 May 2015 / Accepted: 5 October 2015.</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>A researcher can infer mathematical expressions of functions quickly by using his professional knowledge (called Prior Knowledge). But the results he finds may be biased and restricted to his research field due to limitation of his knowledge. In contrast, Genetic Programming method can discover fitted mathematical expressions from the huge search space through running evolutionary algorithms. And its results can be generalized to accommodate different fields of knowledge. However, since GP has to search a huge space, its speed of finding the results is rather slow. Therefore, in this paper, a framework of connection between Prior Formula Knowledge and GP (PFK-GP) is proposed to reduce the space of GP searching. The PFK is built based on the Deep Belief Network (DBN) which can identify candidate formulas that are consistent with the features of experimental data. By using these candidate formulas as the seed of a randomly generated population, PFK-GP finds the right formulas quickly by exploring the search space of data features. We have compared PFK-GP with Pareto GP on regression of eight benchmark problems. The experimental results confirm that the PFK-GP can reduce the search space and obtain the significant improvement in the quality of SR.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://downloads.hindawi.com/journals/cin/2016/1021378.pdf">Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>演化计算和符号回归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>演化计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Enhancing Gene Expression Programming based on Space Partition and Jump for Symbolic Regression, Information Sciences</title>
    <link href="/2021/06/18/Enhancing-Gene-Expression-Programming-based-on-Space-Partition-and-Jump-for-Symbolic-Regression-Information-Sciences/"/>
    <url>/2021/06/18/Enhancing-Gene-Expression-Programming-based-on-Space-Partition-and-Jump-for-Symbolic-Regression-Information-Sciences/</url>
    
    <content type="html"><![CDATA[<p>Lu Q, Zhou S, Tao F, Luo J, Wang ZG.</p><p>Received: 23 April 2019 / Accepted: 18  August 2020.</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>When solving a symbolic regression problem, the gene expression programming (GEP)algorithm could fall into a premature convergence which terminates the optimization pro-cess too early, and may only reach a poor local optimum. To address the premature conver-gence problem of GEP, we propose a novel algorithm named SPJ-GEP, which can maintainthe GEP population diversity and improve the accuracy of the GEP search by allowing thepopulation to jump efficiently between segmented subspaces. SPJ-GEP first divides thespace of mathematical expressions intoksubspaces that are mutually exclusive. It thencreates a subspace selection method that combines the multi-armed bandit and the-greedy strategy to choose a jump subspace. In this way, the analysis is made on the pop-ulation diversity and the range of the number of subspaces. The analysis results show thatSPJ-GEP does not significantly increase the computational complexity of time and spacethan classical GEP methods. Besides, an evaluation is conducted on a set of standard SRbenchmarks. The evaluation results show that the proposed SPJ-GEP keeps a higher popu-lation diversity and has an enhanced accuracy compared with three baseline GEP methods.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://www.sciencedirect.com/science/article/pii/S0020025520308276">Sciencedirect-Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP">Code</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>演化计算和符号回归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>演化计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>About KGAE</title>
    <link href="/2021/06/09/About-KGAE/"/>
    <url>/2021/06/09/About-KGAE/</url>
    
    <content type="html"><![CDATA[<h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><p>谷歌学术：<a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=m61aeIAAAAAJ">https://scholar.google.com/citations?hl=zh-CN&amp;user=m61aeIAAAAAJ</a></p><p>邮箱：<a href="mailto:&#x6c;&#117;&#113;&#105;&#x61;&#x6e;&#103;&#64;&#99;&#117;&#112;&#x2e;&#101;&#100;&#117;&#x2e;&#99;&#x6e;">&#x6c;&#117;&#113;&#105;&#x61;&#x6e;&#103;&#64;&#99;&#117;&#112;&#x2e;&#101;&#100;&#117;&#x2e;&#99;&#x6e;</a>; <a href="mailto:&#108;&#117;&#x71;&#105;&#97;&#110;&#x67;&#116;&#111;&#110;&#x79;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#109;">&#108;&#117;&#x71;&#105;&#97;&#110;&#x67;&#116;&#111;&#110;&#x79;&#64;&#x67;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#109;</a></p><p>欢迎来到<a href="https://mp.weixin.qq.com/s/urEqo_WQ56_W7Iitugt8ag">KGAE</a>实验室！</p><p>在这里可以教会你<a href="https://hexo.fluid-dev.com/">如何快速编辑一篇好看的文章</a>，对于配置一些好看的插件，可以参考<a href="https://hexo.fluid-dev.com/docs/guide">guide</a></p>]]></content>
    
    
    <categories>
      
      <category>实验室简介</category>
      
    </categories>
    
    
    <tags>
      
      <tag>说明</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Incorporating Actor-Critic in Monte Carlo tree search for symbolic regression</title>
    <link href="/2021/06/09/Incorporating%20Actor-Critic%20in%20Monte%20Carlo%20tree%20search%20for%20symbolic/"/>
    <url>/2021/06/09/Incorporating%20Actor-Critic%20in%20Monte%20Carlo%20tree%20search%20for%20symbolic/</url>
    
    <content type="html"><![CDATA[<p>Qiang Lu, Fan Tao, Shuo Zhou &amp; Zhiguang Wang.</p><p>Received: 29 May 2020 / Accepted: 11 December 2020.</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Most traditional genetic programming methods that handle symbolic regression are random algorithms without memory and direction. They repeatedly search for the same or similar positions in the symbolic space, and easily fall into premature convergence. To overcome these shortcomings, we propose a new symbolic expression search algorithm based on the Monte Carlo tree search named SE-MCTS. It creates a tree to represent the symbolic space and remembers its visiting positions. Moreover, it incorporates two neural networks—Actor and Critic into the upper confidence bound to direct its search based on the given dataset features and decide when to use particle swarm optimization to find fitted constants in a mathematical expression. The experiment results show that SE-MCTS can discover more proper mathematical expressions than canonical genetic programming methods.</p><h2 id="More-info-about-thie-paper"><a href="#More-info-about-thie-paper" class="headerlink" title="More info about thie paper"></a>More info about thie paper</h2><p>Please see <a href="https://link.springer.com/article/10.1007/s00521-020-05602-2">Springer-Link</a></p><h2 id="Code-Link"><a href="#Code-Link" class="headerlink" title="Code Link"></a>Code Link</h2><p>Please see <a href="https://github.com/KGAE-CUP/SE-MCTS">SE-MCTS</a> on our GitHub.</p>]]></content>
    
    
    <categories>
      
      <category>演化计算和符号回归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>演化计算+深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
